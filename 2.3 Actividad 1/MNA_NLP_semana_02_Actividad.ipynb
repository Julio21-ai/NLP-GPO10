{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "759SG4TyfbUn",
        "Zj-h4drXD-X9",
        "BY6yifxscfrx",
        "k_ewoagic5jc",
        "70StdqAZa9E9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KlBCClnau5-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Evidence 3](https://i.imgur.com/mu6ZuGT.jpg)\n",
        "\n",
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Procesamiento de Lenguaje Natural (NLP)**\n",
        "###Tecnológico de Monterrey\n",
        "###Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Adtividad de la Semana 02**\n",
        "###**Introducción al procesamiento de texto.**\n",
        "\n",
        "##**Julio Baltazar Colín: A01794476**"
      ],
      "metadata": {
        "id": "759SG4TyfbUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta actividad deberás utilizar los datos del siguiente archivo que se encuentra en Canvas:\n",
        "\n",
        "MNA_NLP_semana_02_Actividad_datos.txt\n",
        "\n",
        "El archivo contiene comentarios en inglés sobre servicios de comida de la página de Yelp: https://www.yelp.com/ .\n",
        "\n",
        "Son mil comentarios y forman parte del conjunto de datos que se encuentra en el Machine Learning Repository de la UCI, llamado \"Sentiment Labelled Sentences\": https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#\n"
      ],
      "metadata": {
        "id": "6ue1YAKx3XDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 1. Cargamos los datos.**   "
      ],
      "metadata": {
        "id": "Zj-h4drXD-X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar los datos del archivo indicado y obtener una lista de longitud de 1000 strings/comentarios.\n",
        "\n",
        "Por el momento solamente requerimos las bibliotecas de Numpy y re, para el manejo de los arreglos y de las expresiones regulares en Python.\n",
        "\n",
        "En particular, no necesitarás en esta actividad la biblioteca de Pandas.\n",
        "\n",
        "###**NOTA: En esta actividad no debes importar nada más, con estas dos bibliotecas será *suficiente*.**"
      ],
      "metadata": {
        "id": "BY6yifxscfrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np    # importamos Numpy para el manejo de los arreglos.\n",
        "import re             # importamos re para el manejo de las expresiones regulares."
      ],
      "metadata": {
        "id": "OJ26dAfhdFnf"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/Julio21-ai/NLP-GPO10/main/2.3%20Actividad%201/MNA_NLP_semana_02_Actividad_datos.txt'\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200: #200 = OK\n",
        "    docs = response.text.splitlines()  ## separamos cada comentario por líneas\n",
        "else:\n",
        "    print(\"Error al obtener el archivo:\", response.status_code)"
      ],
      "metadata": {
        "id": "zd5TQsvBGSka"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(docs) == list   # Verifica que tu variable \"docs\" es una lista"
      ],
      "metadata": {
        "id": "L6WzrSrodG-Y",
        "outputId": "8376f9ee-8141-4c05-c11e-3199198597cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)==1000  # verifica que la longitud de \"docs\" es de mil comentarios."
      ],
      "metadata": {
        "id": "QIK1u9WS2FtS",
        "outputId": "dcc18a92-9667-4765-8138-057d79e1a43e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0:10]     # observa algunos de los primeros comentarios"
      ],
      "metadata": {
        "id": "9AMLIfQvJqNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f71d87-36f4-4503-a536-b43ac9d0992c"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.',\n",
              " 'Crust is not good.',\n",
              " 'Not tasty and the texture was just nasty.',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
              " 'The selection on the menu was great and so were the prices.',\n",
              " 'Now I am getting angry and I want my damn pho.',\n",
              " \"Honeslty it didn't taste THAT fresh.)\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
              " 'The fries were great too.',\n",
              " 'A great touch.']"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 2: sección de preguntas (regex).**   \n"
      ],
      "metadata": {
        "id": "k_ewoagic5jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Instrucciones:**\n",
        "\n",
        "###**A continuación deberás contestar cada una de las preguntas que te piden usando expresiones regulares (regex).**\n",
        "\n",
        "###**Por el momento no hay restricción en cuanto al número de líneas de código que agregues, pero trata de incluir las mínimas posibles.**"
      ],
      "metadata": {
        "id": "X-eMJa3DFCIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 1.**\n",
        "\n",
        "Busca y elimina todos los saltos de línea '\\n' que se encuentran al final de cada comentario.\n",
        "\n",
        "Una vez finalizado, imprime los primeros 10 comentarios del resultado obtenido.\n"
      ],
      "metadata": {
        "id": "78nJMemzn5a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar los saltos de línea del texto original (limpieza).\n",
        "comentarios = [re.sub(r'\\n', '', comentario) for comentario in docs]\n",
        "# Mostrar los primeros 10 elementos resultantes.\n",
        "comentarios[0:10]"
      ],
      "metadata": {
        "id": "PwbYYIuZn8pE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c575f9-071d-4776-ea28-26e8985b2fd2"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.',\n",
              " 'Crust is not good.',\n",
              " 'Not tasty and the texture was just nasty.',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
              " 'The selection on the menu was great and so were the prices.',\n",
              " 'Now I am getting angry and I want my damn pho.',\n",
              " \"Honeslty it didn't taste THAT fresh.)\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
              " 'The fries were great too.',\n",
              " 'A great touch.']"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 2.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan con dos o más signos de admiración seguidos, por ejemplo \"!!!\".\n",
        "\n",
        "Debes imprimir tanto la palabra como la totalidad de signos de admiración que le siguen.\n",
        "\n",
        "Indica cuántos resultados obtuviste.\n",
        "\n"
      ],
      "metadata": {
        "id": "VWeKQC93ctEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar el patrón de la expresión regular:\n",
        "  # \\w+ caracteres alfanuméricos y guiones bajos una o más veces\n",
        "  # !!+ dos o más coincidencias de signos de admiración\n",
        "expresion_regular = r'\\w+!!+'\n",
        "\n",
        "# Obtener los resultados:\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias\n",
        "print(\"Número total de coincidencias:\", len(matches))"
      ],
      "metadata": {
        "id": "0p3kMXfddICc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c342083-85d7-4879-ae3f-6fd21473452b"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for match in matches:\n",
        "    print(match)"
      ],
      "metadata": {
        "id": "SPVM1MCWdH6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c18ad9-f9d0-409b-b4dc-a43ee5837e0d"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Firehouse!!!!!\n",
            "APPETIZERS!!!\n",
            "amazing!!!\n",
            "buffet!!!\n",
            "good!!\n",
            "it!!!!\n",
            "DELICIOUS!!\n",
            "amazing!!\n",
            "shawarrrrrrma!!!!!!\n",
            "yucky!!!\n",
            "steak!!!!!\n",
            "delicious!!!\n",
            "far!!\n",
            "biscuits!!!\n",
            "dry!!\n",
            "disappointing!!!\n",
            "awesome!!\n",
            "Up!!\n",
            "FLY!!!!!!!!\n",
            "here!!!\n",
            "great!!!!!!!!!!!!!!\n",
            "packed!!\n",
            "otherwise!!\n",
            "amazing!!!!!!!!!!!!!!!!!!!\n",
            "style!!\n",
            "disappointed!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 3.**  \n",
        "\n",
        "Busca e imprime todas las palabras que están escritas totalmente en mayúsculas. Cada coincidencia debe ser una sola palabra.\n",
        "\n",
        "Indica cuántas palabras encontraste.\n",
        "\n"
      ],
      "metadata": {
        "id": "-s3okBqL96TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Búsqueda de todas las palabras que están escritas totalmente en mayúsculas.\n",
        "  # \\b: límite de palabra\n",
        "  # [A-Z]: caracteres en mayúsculas incluyendo números\n",
        "  # \\b: límite de palabra\n",
        "expresion_regular = r'\\b[A-Z]+\\b'\n",
        "\n",
        "# Obtener los resultados:\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias\n",
        "print(\"Número total de coincidencias:\", len(matches))"
      ],
      "metadata": {
        "id": "yKHJkZKo_nW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91bb52b-c167-425c-d71f-b82f4ebe8fae"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias: 455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "id": "L3q08aq69sNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826d5d56-bf7d-4835-d90a-c82693bb5ed3"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "I\n",
            "THAT\n",
            "A\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "APPETIZERS\n",
            "A\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "WILL\n",
            "NEVER\n",
            "EVER\n",
            "STEP\n",
            "FORWARD\n",
            "IN\n",
            "IT\n",
            "AGAIN\n",
            "I\n",
            "LOVED\n",
            "I\n",
            "AND\n",
            "REAL\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "BITCHES\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "NYC\n",
            "I\n",
            "I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminando las letras únicas como \"I\" (Yo) o A que se repiten varias veces\n",
        "# y letras mayúsculas sueltas:\n",
        "# Generar el patrón de la expresión regular:\n",
        "  # \\b: límite de palabra\n",
        "  # (?![A-Z]\\b): no permitir letras sueltas como la palabra \"I\"\n",
        "  # [A-Z]: caracteres en mayúsculas\n",
        "  # \\b: límite de palabra\n",
        "expresion_regular = r'\\b(?![A-Z]\\b)[A-Z]+\\b'\n",
        "\n",
        "# Obtener los resultados:\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias\n",
        "print(\"Número total de coincidencias:\", len(matches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0QnHpCwt1_m",
        "outputId": "8f82bd95-cb6a-4c27-bc65-3a21d91c28d7"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias: 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJBAoSILuqSj",
        "outputId": "c63565fe-603f-4f29-fee6-b4da6cc1ceda"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THAT\n",
            "APPETIZERS\n",
            "WILL\n",
            "NEVER\n",
            "EVER\n",
            "STEP\n",
            "FORWARD\n",
            "IN\n",
            "IT\n",
            "AGAIN\n",
            "LOVED\n",
            "AND\n",
            "REAL\n",
            "BITCHES\n",
            "NYC\n",
            "STALE\n",
            "DELICIOUS\n",
            "WORST\n",
            "EXPERIENCE\n",
            "EVER\n",
            "ALL\n",
            "BARGAIN\n",
            "TV\n",
            "NONE\n",
            "FREEZING\n",
            "AYCE\n",
            "FLAVOR\n",
            "NEVER\n",
            "BBQ\n",
            "UNREAL\n",
            "OMG\n",
            "BETTER\n",
            "BLAND\n",
            "RUDE\n",
            "INCONSIDERATE\n",
            "MANAGEMENT\n",
            "WILL\n",
            "NEVER\n",
            "EVER\n",
            "GO\n",
            "BACK\n",
            "AND\n",
            "HAVE\n",
            "TOLD\n",
            "MANY\n",
            "PEOPLE\n",
            "WHAT\n",
            "HAD\n",
            "HAPPENED\n",
            "TOTAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 4.**  \n",
        "\n",
        "Busca e imprime los comentarios en donde todos los caracteres alfabéticos (letras) están en mayúsculas.\n",
        "\n",
        "Cada coincidencia encontrada debe ser todo el comentario/enunciado.\n",
        "\n",
        "Indica cuántos resultados obtuviste.\n"
      ],
      "metadata": {
        "id": "GX8eYyDoMZma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscar todas las coincidencias que no sean completamente en minúsculas:\n",
        "# ^[^a-z]*$: Descartar si hay caracteres en minúsculas, preservando puntuaciones.\n",
        "expresion_regular = r'^[^a-z]*$'\n",
        "\n",
        "# Obtener los resultados:\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias\n",
        "print(\"Número total de coincidencias:\", len(matches))"
      ],
      "metadata": {
        "id": "K8VuZxvTMYj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b7045c-cb10-4167-ef90-f7c3e9ef8705"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "id": "PmKgX7sCMcDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3010cd-c24a-4937-81e1-3b3a44703b46"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DELICIOUS!!\n",
            "RUDE & INCONSIDERATE MANAGEMENT.\n",
            "WILL NEVER EVER GO BACK AND HAVE TOLD MANY PEOPLE WHAT HAD HAPPENED.\n",
            "TOTAL WASTE OF TIME.\n",
            "AVOID THIS ESTABLISHMENT!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 5.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una vocal acentuada, del tipo á, é, í, ó, ú.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "a1i6qv7-McmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscar todas las coincidencias de palabras que contienen las letras con tilde: á, é, í, ó, ú\n",
        "expresion_regular = r'\\b\\w*[áéíóú]+\\w*\\b'\n",
        "\n",
        "# Obtener los resultados:\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias\n",
        "print(\"Número total de coincidencias:\", len(matches))\n"
      ],
      "metadata": {
        "id": "nZZ5zKUOMeGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb9bd6f-59d7-4517-e6f2-b50bb0ad97b0"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "id": "l1mFvUEZMe8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c0d994-63fe-48bf-8592-d78a4aa17b5e"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fiancé\n",
            "Café\n",
            "puréed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 6.**  \n",
        "\n",
        "Busca e imprime todas las cantidades numéricas monetarias, enteras o con decimales, que inician con el símbolo $\\$$.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "ZmPiAI82Mfb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscar todas las coincidencias numéricas monetarias, enteras o con decimales, que inicien con el símbolo $\n",
        "# \\$: El símbolo de moneda\n",
        "# \\d+: Uno o más dígitos\n",
        "# (?:,\\d{3})*: Opcionalmente una coma seguida de tres dígitos, repetido cero o más veces\n",
        "# (?:\\.\\d+)?: Opcionalmente un punto seguido de uno o más dígitos\n",
        "expresion_regular = r'\\$\\d+(?:,\\d{3})*(?:\\.\\d+)?'\n",
        "\n",
        "# Obtener los resultados:\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias\n",
        "print(\"Número total de coincidencias:\", len(matches))\n"
      ],
      "metadata": {
        "id": "6vhe9-Y-MhL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12dfb4ea-8b91-4c73-ae2e-59fb9156e895"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "id": "_t0a5xWDMhQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a5c5d2-90db-4566-8b11-bdff0256f674"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$20\n",
            "$4.00\n",
            "$17\n",
            "$3\n",
            "$35\n",
            "$7.85\n",
            "$12\n",
            "$11.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 7.**  \n",
        "\n",
        "Busca e imprime todas las palabras que sean variantes de la palabra \"love\", sin importar si incluyen mayúsculas o minúsculas, o la manera en que esté conjugada o alguna otra variación que se haga con dicha palabra.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "2j-HpvhwMhq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscar variantes de la palabra \"love\", sin importar si incluyen mayúsculas o minúsculas:\n",
        "# \\b: límite de palabra\n",
        "# [Ll1][O0o][Vv][Ee3]: Variaciones posibles de la palabra \"love\" incluyendo diferentes combinaciones de mayúsculas y minúsculas, así como dígitos.\n",
        "# \\w*: Cero o más caracteres alfanuméricos que siguen la palabra \"love\"\n",
        "# \\b: límite de palabra\n",
        "expresion_regular = r'\\b[Ll1][O0o][Vv][Ee3]\\w*\\b'\n",
        "\n",
        "# Obtener los resultados:\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias\n",
        "print(\"Número total de coincidencias:\", len(matches))\n"
      ],
      "metadata": {
        "id": "kqqyRChVMjol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed78cc05-d26a-4aa2-df6a-67a0e0ce17cf"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "id": "2jFBr_mLwDMp",
        "outputId": "5a851c4f-653f-41af-d925-4a59783f2092",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loved\n",
            "loved\n",
            "Loved\n",
            "love\n",
            "loves\n",
            "LOVED\n",
            "lovers\n",
            "love\n",
            "lovers\n",
            "Love\n",
            "loved\n",
            "loved\n",
            "love\n",
            "love\n",
            "love\n",
            "loved\n",
            "love\n",
            "loved\n",
            "Love\n",
            "LOVED\n",
            "love\n",
            "lovely\n",
            "love\n",
            "lovely\n",
            "love\n",
            "lover\n",
            "loved\n",
            "love\n",
            "love\n",
            "love\n",
            "love\n",
            "love\n",
            "love\n",
            "love\n",
            "love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 8.**  \n",
        "\n",
        "Busca e imprime todas las palabras, variantes de \"so\" y \"good\", que tengan dos o más \"o\" en \"so\" y 3 o más \"o\" en good.\n",
        "\n",
        "Indica cuántas encontraste.\n"
      ],
      "metadata": {
        "id": "Ctb-NTY3MkYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variantes de \"so\", que contienen dos o más ocurrencias de la letra \"o\" en \"so\":\n",
        "# \\b: Coincide con un límite de palabra.\n",
        "# ([Ss]): Coincide con una o más ocurrencias de la letra \"s\" en mayúscula o minúscula.\n",
        "# [Oo]{2,}: Coincide con dos o más ocurrencias de la letra \"o\" en mayúscula o minúscula.\n",
        "# \\b: Coincide con un límite de palabra.\n",
        "expresion_regular = r'\\b([Ss]+[Oo]{2,})+\\b'\n",
        "\n",
        "# matches: Lista que contiene todas las coincidencias encontradas en los comentarios.\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias.\n",
        "print(\"Número total de coincidencias de 'so':\", len(matches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvl-0gjzxQML",
        "outputId": "dbc2ef11-d495-4933-9f37-8ebeb7465b0d"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias de 'so': 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "id": "svS4-vvPMl6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022cea8e-b298-4246-8999-079852a82f0c"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sooooo\n",
            "soooo\n",
            "soooooo\n",
            "soooo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variantes de \"good\", que contienen 3 o más ocurrencias de la letra \"o\" en \"good\":\n",
        "# \\b: Coincide con un límite de palabra.\n",
        "# [Gg]: Coincide con una o más ocurrencias de la letra \"g\" en mayúscula o minúscula.\n",
        "# [Oo]{3,}: Coincide con tres o más ocurrencias de la letra \"o\" en mayúscula o minúscula.\n",
        "# [Dd]+: Coincide con una o más ocurrencias de la letra \"d\" en mayúscula o minúscula.\n",
        "# \\b: Coincide con un límite de palabra.\n",
        "expresion_regular = r'\\b[Gg]+[Oo]{3,}[Dd]+\\b'\n",
        "\n",
        "# matches: Lista que contiene todas las coincidencias encontradas en los comentarios.\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias.\n",
        "print(\"Número total de coincidencias de 'good':\", len(matches))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7UMkLr5wi5U",
        "outputId": "bb43495f-9e72-4d8c-827b-9b15ffd63645"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias de 'good': 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbEMr2qczlsp",
        "outputId": "c5b0c883-6375-4781-a519-1ed48457d6a6"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gooodd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 9.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una longitud mayor estrictamente a 10 caracteres alfabéticos.\n",
        "\n",
        "No se consideran los signos de puntuación o caracteres especiales en la longitud de estas cadenas, solo caracteres alfabéticos en mayúsculas o minúsculas.\n",
        "\n",
        "Indica la cantidad de palabras encontradas.\n"
      ],
      "metadata": {
        "id": "hkak1opjMmlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que tengan una longitud mayor estrictamente a 10 caracteres alfabéticos:\n",
        "# \\b: Coincide con un límite de palabra.\n",
        "# [a-zA-Z]: Coincide con cualquier letra en mayúscula o minúscula.\n",
        "# {11,}: Indica que la longitud de la palabra debe ser mayor o igual a 11 caracteres.\n",
        "# \\b: Coincide con un límite de palabra.\n",
        "expresion_regular = r'\\b[a-zA-Z]{11,}\\b'\n",
        "\n",
        "# matches: Lista que contiene todas las coincidencias encontradas en los comentarios.\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias.\n",
        "print(\"Número total de palabras con longitud mayor a 10 caracteres alfabéticos:\", len(matches))\n"
      ],
      "metadata": {
        "outputId": "e95f522a-0f79-475e-df34-220ab2ab0c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDlqeZ1h3OwQ"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de palabras con longitud mayor a 10 caracteres alfabéticos: 141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0cuQHcP3s5W",
        "outputId": "235cac3c-3957-455e-e1c6-b1c2e54869e6"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recommendation\n",
            "recommended\n",
            "overwhelmed\n",
            "inexpensive\n",
            "establishment\n",
            "imaginative\n",
            "opportunity\n",
            "experiencing\n",
            "underwhelming\n",
            "relationship\n",
            "unsatisfying\n",
            "disappointing\n",
            "outrageously\n",
            "disappointing\n",
            "expectations\n",
            "restaurants\n",
            "suggestions\n",
            "disappointed\n",
            "considering\n",
            "Unfortunately\n",
            "immediately\n",
            "ingredients\n",
            "accommodations\n",
            "maintaining\n",
            "Interesting\n",
            "disrespected\n",
            "accordingly\n",
            "unbelievable\n",
            "cheeseburger\n",
            "descriptions\n",
            "inexpensive\n",
            "disappointed\n",
            "Veggitarian\n",
            "outstanding\n",
            "recommendation\n",
            "disappointed\n",
            "disappointed\n",
            "neighborhood\n",
            "disappointed\n",
            "corporation\n",
            "considering\n",
            "exceptional\n",
            "shawarrrrrrma\n",
            "disappointed\n",
            "vinaigrette\n",
            "immediately\n",
            "unbelievably\n",
            "replenished\n",
            "disappointed\n",
            "enthusiastic\n",
            "Outstanding\n",
            "comfortable\n",
            "interesting\n",
            "INCONSIDERATE\n",
            "considering\n",
            "transcendant\n",
            "disappointment\n",
            "disappointed\n",
            "disappointed\n",
            "overwhelmed\n",
            "professional\n",
            "Furthermore\n",
            "combination\n",
            "connoisseur\n",
            "profiterole\n",
            "outstanding\n",
            "acknowledged\n",
            "ventilation\n",
            "beautifully\n",
            "establishment\n",
            "extraordinary\n",
            "disappointed\n",
            "cheesecurds\n",
            "disappointed\n",
            "interesting\n",
            "experienced\n",
            "opportunity\n",
            "disgraceful\n",
            "restaurants\n",
            "ESTABLISHMENT\n",
            "recommended\n",
            "disappointed\n",
            "recommended\n",
            "acknowledged\n",
            "presentation\n",
            "Philadelphia\n",
            "disappointed\n",
            "disappointing\n",
            "grandmother\n",
            "drastically\n",
            "informative\n",
            "Disappointed\n",
            "constructed\n",
            "comfortable\n",
            "Smashburger\n",
            "cheeseburger\n",
            "neighborhood\n",
            "disappointed\n",
            "hospitality\n",
            "recommending\n",
            "disappointed\n",
            "deliciously\n",
            "compliments\n",
            "recommendation\n",
            "establishment\n",
            "calligraphy\n",
            "traditional\n",
            "combination\n",
            "Unfortunately\n",
            "Wienerschnitzel\n",
            "unfortunately\n",
            "considering\n",
            "highlighted\n",
            "Mediterranean\n",
            "unprofessional\n",
            "anticipated\n",
            "disappointing\n",
            "unexperienced\n",
            "disrespected\n",
            "professional\n",
            "restaurants\n",
            "Disappointing\n",
            "WAAAAAAyyyyyyyyyy\n",
            "reservation\n",
            "imagination\n",
            "undercooked\n",
            "disappointed\n",
            "disappointment\n",
            "disappointment\n",
            "deuchebaggery\n",
            "disappointed\n",
            "disappointment\n",
            "immediately\n",
            "Unfortunately\n",
            "disapppointment\n",
            "circumstances\n",
            "undercooked\n",
            "caterpillar\n",
            "presentation\n",
            "disappointed\n",
            "underwhelming\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 10.**  \n",
        "\n",
        "Busca e imprime todas las palabras que inician con una letra mayúscula y terminan con una minúscula, pero que además no sea la primera palabra del comentario/string.\n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "ApjTNzSxMpDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar la primera palabra\n",
        "# \\b: Coincide con el límite de una palabra.\n",
        "# \\w+: Coincide con uno o más caracteres alfanuméricos.\n",
        "# \\b: Coincide con el límite de una palabra.\n",
        "patron_primera_palabra = r'\\b\\w+\\b'\n",
        "\n",
        "enunciados_sin_primera_palabra = []\n",
        "\n",
        "for enunciado in comentarios:\n",
        "    # Encuentra la primera palabra del enunciado\n",
        "    primera_palabra = re.match(patron_primera_palabra, enunciado)\n",
        "\n",
        "    if primera_palabra:\n",
        "        # Obtiene la posición del final de la primera palabra\n",
        "        fin_primera_palabra = primera_palabra.end()\n",
        "\n",
        "        # Elimina la primera palabra del enunciado y lo procesa\n",
        "        enunciado_sin_primera_palabra = enunciado[fin_primera_palabra:].strip()\n",
        "\n",
        "        # Agrega el enunciado procesado a la lista\n",
        "        enunciados_sin_primera_palabra.append(enunciado_sin_primera_palabra)\n",
        "\n",
        "# Imprime la lista de enunciados sin la primera palabra\n",
        "for enunciado in enunciados_sin_primera_palabra[:10]:\n",
        "  print(\"Enunciados sin la primera palabra:\", enunciado)\n"
      ],
      "metadata": {
        "id": "dLPTRPnTMqqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bac523c-3757-490e-a2f1-3e5768e375f5"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enunciados sin la primera palabra: ... Loved this place.\n",
            "Enunciados sin la primera palabra: is not good.\n",
            "Enunciados sin la primera palabra: tasty and the texture was just nasty.\n",
            "Enunciados sin la primera palabra: by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
            "Enunciados sin la primera palabra: selection on the menu was great and so were the prices.\n",
            "Enunciados sin la primera palabra: I am getting angry and I want my damn pho.\n",
            "Enunciados sin la primera palabra: it didn't taste THAT fresh.)\n",
            "Enunciados sin la primera palabra: potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\n",
            "Enunciados sin la primera palabra: fries were great too.\n",
            "Enunciados sin la primera palabra: great touch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Procesamiento:\n",
        "\n",
        "# Expresión regular que busca palabras que comienzan con una letra mayúscula y terminan con una minúscula\n",
        "#   [A-Z]+: Coincide con una o más letras mayúsculas al principio de la palabra.\n",
        "#   \\w*: Coincide con cero o más caracteres alfanuméricos (letras, dígitos o guiones bajos).\n",
        "#   [a-z]+: Coincide con una o más letras minúsculas al final de la palabra.\n",
        "expresion_regular = r'([A-Z]+\\w*[a-z]+)'\n",
        "\n",
        "# Coincidencias encontradas en los enunciados sin la primera palabra\n",
        "matches = [match for commentario in enunciados_sin_primera_palabra for match in re.findall(expresion_regular, commentario)]\n",
        "\n",
        "# Imprimir el número total de coincidencias\n",
        "print(\"Número total de coincidencias de palabras que inician con una letra mayúscula y terminan con una minúscula:\", len(matches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QqQxcPL3Lne",
        "outputId": "3bd27662-20f3-4b0f-9608-fdf27f1e7d4e"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de coincidencias de palabras que inician con una letra mayúscula y terminan con una minúscula: 165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 50 primeras coincidencias\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZofDS5CJ5gO",
        "outputId": "dab300e4-5c23-463b-f5bb-94798cc9d7d3"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loved\n",
            "May\n",
            "Rick\n",
            "Steve\n",
            "Burrittos\n",
            "Blah\n",
            "The\n",
            "Hiro\n",
            "Firehouse\n",
            "Heart\n",
            "Attack\n",
            "Grill\n",
            "Vegas\n",
            "Dos\n",
            "Gringos\n",
            "Very\n",
            "Bad\n",
            "Customer\n",
            "Service\n",
            "Vegas\n",
            "Rice\n",
            "Company\n",
            "Pho\n",
            "Tigerlilly\n",
            "Thai\n",
            "Indian\n",
            "Not\n",
            "Vegas\n",
            "Mandalay\n",
            "Bay\n",
            "Great\n",
            "Voodoo\n",
            "Phoenix\n",
            "Lemon\n",
            "Joey\n",
            "Valley\n",
            "Phoenix\n",
            "Magazine\n",
            "Pho\n",
            "Fridays\n",
            "Tasty\n",
            "Jamaican\n",
            "Otto\n",
            "Not\n",
            "Vegas\n",
            "Greek\n",
            "Veggitarian\n",
            "Bachi\n",
            "Burger\n",
            "Pizza\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 11.**  \n",
        "\n",
        "Busca e imprime la secuencia de dos o más palabras que están separadas por un guion, \"-\", sin que tengan espacios en blanco entre ellas.\n",
        "\n",
        "Por ejemplo \"Go-Kart\" sería válido, pero \"Go  -Kart\" o \"Go  -  Kart\" no lo serían.\n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "u7nfm4KhMrNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expresión regular para encontrar palabras separadas por un guion \"-\", sin espacios en blanco entre ellas:\n",
        "# \\b: Coincide con un límite de palabra.\n",
        "# \\w+-\\w+: Coincide con una palabra que contiene un guion \"-\" seguido por otra palabra.\n",
        "# \\b: Coincide con un límite de palabra.\n",
        "expresion_regular = r'\\b\\w+-\\w+\\b'\n",
        "\n",
        "# matches: Lista que contiene todas las coincidencias encontradas en los comentarios.\n",
        "matches = [match for comentario in comentarios for match in re.findall(expresion_regular, comentario)]\n",
        "\n",
        "# Obtener el total de coincidencias.\n",
        "print(\"Número total de palabras separadas por un guion sin espacios en blanco entre ellas:\", len(matches))\n"
      ],
      "metadata": {
        "id": "OwU-a7eGMsub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca27aa98-9073-49c8-f957-4092150b34ce"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de palabras separadas por un guion sin espacios en blanco entre ellas: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for match in matches:\n",
        "    print(match)"
      ],
      "metadata": {
        "id": "SgzIL74ZMtGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1aa511-2560-4633-f1ee-d53d7f69436c"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flat-lined\n",
            "hands-down\n",
            "must-stop\n",
            "sub-par\n",
            "Service-check\n",
            "in-house\n",
            "been-stepped\n",
            "in-and\n",
            "tracked-everywhere\n",
            "multi-grain\n",
            "to-go\n",
            "non-customer\n",
            "High-quality\n",
            "sit-down\n",
            "over-whelm\n",
            "low-key\n",
            "non-fancy\n",
            "golden-crispy\n",
            "over-priced\n",
            "over-hip\n",
            "under-services\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 12.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan en \"ing\" o \"ed\".\n",
        "\n",
        "Indica la cantidad de palabras que encontraste de cada una."
      ],
      "metadata": {
        "id": "DEIgl79HMthr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expresión regular para buscar palabras que terminan en \"ing\" o \"ed\"\n",
        "expresion_regular = r'\\b\\w+(?:ing|ed)\\b'\n",
        "\n",
        "# Busca todas las coincidencias en el texto\n",
        "matches = [match for commentario in comentarios for match in re.findall(expresion_regular, commentario)]\n",
        "\n",
        "# Inicializa contadores para palabras terminadas en \"ing\" y \"ed\"\n",
        "cont_ing = 0\n",
        "cont_ed = 0\n",
        "\n",
        "# Itera sobre las coincidencias para contar la cantidad de palabras encontradas\n",
        "for palabra in matches:\n",
        "    if palabra.endswith(\"ing\"):\n",
        "        cont_ing += 1\n",
        "    elif palabra.endswith(\"ed\"):\n",
        "        cont_ed += 1\n",
        "\n",
        "# Imprime las palabras encontradas y la cantidad de cada una\n",
        "print(\"Palabras que terminan en 'ing':\", cont_ing)\n",
        "print(\"Palabras que terminan en 'ed':\", cont_ed)\n"
      ],
      "metadata": {
        "id": "I4TSofBMMv9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf00170-87a6-4d20-9039-493786aa1770"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que terminan en 'ing': 279\n",
            "Palabras que terminan en 'ed': 335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expresión regular para buscar palabras que terminan en \"ing\" o \"ed\":\n",
        "# \\b: Coincide con un límite de palabra para asegurar que la palabra esté delimitada correctamente.\n",
        "# \\w+: Coincide con una o más letras, dígitos o guiones bajos al principio de la palabra.\n",
        "# (?:ing|ed): Grupo de no captura que coincide con la secuencia \"ing\" o \"ed\".\n",
        "#  cualquier coincidencia encontrada dentro de este grupo no se capturará como un grupo separado\n",
        "# \\b: Coincide con un límite de palabra para asegurar que la palabra esté delimitada correctamente.\n",
        "expresion_regular = r'\\b\\w+(?:ing|ed)\\b'\n",
        "\n",
        "# Busca todas las coincidencias en el texto\n",
        "matches = [match for commentario in comentarios for match in re.findall(expresion_regular, commentario)]\n",
        "\n",
        "# Inicializa contadores para palabras terminadas en \"ing\" y \"ed\"\n",
        "cont_ing = sum(1 for palabra in matches if palabra.endswith(\"ing\"))\n",
        "cont_ed = sum(1 for palabra in matches if palabra.endswith(\"ed\"))\n",
        "\n",
        "# Imprime las palabras encontradas y la cantidad de cada una\n",
        "print(\"Palabras que terminan en 'ing':\", cont_ing)\n",
        "print(\"Palabras que terminan en 'ed':\", cont_ed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGKp4-0t4HM3",
        "outputId": "0b27620e-2743-4928-9552-835452c90eae"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que terminan en 'ing': 279\n",
            "Palabras que terminan en 'ed': 335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#primeros 50 resultados\n",
        "for match in matches[:50]:\n",
        "    print(match)"
      ],
      "metadata": {
        "id": "VQqYgQCxM_v4",
        "outputId": "812d18da-8564-4233-c6e5-1adae309a258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loved\n",
            "Stopped\n",
            "during\n",
            "loved\n",
            "getting\n",
            "being\n",
            "ended\n",
            "being\n",
            "overpriced\n",
            "tried\n",
            "disgusted\n",
            "shocked\n",
            "recommended\n",
            "amazing\n",
            "performed\n",
            "red\n",
            "asked\n",
            "running\n",
            "overwhelmed\n",
            "redeeming\n",
            "grossed\n",
            "melted\n",
            "getting\n",
            "provided\n",
            "thing\n",
            "cooked\n",
            "dressing\n",
            "refreshing\n",
            "ordered\n",
            "running\n",
            "realized\n",
            "Loved\n",
            "lined\n",
            "cooked\n",
            "ripped\n",
            "ripped\n",
            "petrified\n",
            "amazing\n",
            "included\n",
            "expected\n",
            "nothing\n",
            "appalling\n",
            "seasoned\n",
            "cheated\n",
            "wasting\n",
            "eating\n",
            "going\n",
            "Coming\n",
            "experiencing\n",
            "underwhelming\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 3. Proceso de limpieza.**"
      ],
      "metadata": {
        "id": "70StdqAZa9E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 13.**  \n",
        "\n",
        "Ahora realiza un proceso de limpieza del corpus que incluya los siguientes procesos:\n",
        "\n",
        "*   Solo se deben considerar caracteres alfabéticos. Es decir, se eliminan todos los signos de puntuación y caracteres especiales.\n",
        "*   Todos los caracteres alfabéticos se transforman a minúsculas.\n",
        "*   Se deben eliminar todos los espacios en blanco adicionales que se puedan encontrar en cada comentario.\n",
        "\n",
        "Al finalizar dicho proceso de limpieza, imprime el resultado de los primeros 10 comentarios resultantes.\n",
        "   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xaDUFXHrMvX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminación de los signos de puntuación y normalización del texto\n",
        "\n",
        "# comentarios: Lista de comentarios que se van a limpiar y normalizar.\n",
        "# re.sub(r'[^\\w\\s]', '', comentario): Utiliza expresiones regulares para eliminar todos los signos de puntuación del comentario.\n",
        "# .lower(): Convierte todo el texto a minúsculas para una consistencia en el procesamiento.\n",
        "# .strip(): Elimina los espacios en blanco adicionales al principio y al final del texto.\n",
        "comentarios_limpios = [re.sub(r'[^\\w\\s]', '', comentario).lower().strip() for comentario in comentarios]\n"
      ],
      "metadata": {
        "id": "K3kQzPOPMx0w"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 primeros resultados\n",
        "comentarios_limpios[:10]"
      ],
      "metadata": {
        "id": "O3bl4u8VHmp9",
        "outputId": "fca566c3-d53f-4756-ecf7-f8008009a536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wow loved this place',\n",
              " 'crust is not good',\n",
              " 'not tasty and the texture was just nasty',\n",
              " 'stopped by during the late may bank holiday off rick steve recommendation and loved it',\n",
              " 'the selection on the menu was great and so were the prices',\n",
              " 'now i am getting angry and i want my damn pho',\n",
              " 'honeslty it didnt taste that fresh',\n",
              " 'the potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer',\n",
              " 'the fries were great too',\n",
              " 'a great touch']"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 14.**  \n",
        "\n",
        "Con el resultado de la limpieza obtenido en la pregunta anterior, realiza ahora un proceso de tokenización por palabras del corpus.\n",
        "\n",
        "Es decir, al final de este proceso de tokenización, debes tener como resultado una lista de listas, donde cada comentario estará tokenizado por palabras.\n",
        "\n",
        "Al terminar calcula el total de tokens obtenido en todo el corpus."
      ],
      "metadata": {
        "id": "WZwEhg2lUSAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenización por palabras\n",
        "\n",
        "# comentarios_limpios: Lista de comentarios limpios y normalizados.\n",
        "# enunciado.split(): Divide cada comentario en palabras utilizando los espacios en blanco como delimitadores.\n",
        "# tokens_por_enunciado: Lista de listas que contiene los tokens de cada comentario.\n",
        "tokens_por_enunciado = [enunciado.split() for enunciado in comentarios_limpios]\n",
        "\n",
        "# Imprimir los tokens de los primeros 10 comentarios\n",
        "for lista in tokens_por_enunciado[:10]:\n",
        "    print(lista)\n"
      ],
      "metadata": {
        "id": "8HSi_oduMK5o",
        "outputId": "6e752618-6af2-432b-b6d3-3df4df3568a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['wow', 'loved', 'this', 'place']\n",
            "['crust', 'is', 'not', 'good']\n",
            "['not', 'tasty', 'and', 'the', 'texture', 'was', 'just', 'nasty']\n",
            "['stopped', 'by', 'during', 'the', 'late', 'may', 'bank', 'holiday', 'off', 'rick', 'steve', 'recommendation', 'and', 'loved', 'it']\n",
            "['the', 'selection', 'on', 'the', 'menu', 'was', 'great', 'and', 'so', 'were', 'the', 'prices']\n",
            "['now', 'i', 'am', 'getting', 'angry', 'and', 'i', 'want', 'my', 'damn', 'pho']\n",
            "['honeslty', 'it', 'didnt', 'taste', 'that', 'fresh']\n",
            "['the', 'potatoes', 'were', 'like', 'rubber', 'and', 'you', 'could', 'tell', 'they', 'had', 'been', 'made', 'up', 'ahead', 'of', 'time', 'being', 'kept', 'under', 'a', 'warmer']\n",
            "['the', 'fries', 'were', 'great', 'too']\n",
            "['a', 'great', 'touch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cálculo del total de tokens\n",
        "\n",
        "# tokens_por_enunciado: Lista de listas que contiene los tokens de cada comentario.\n",
        "# len(tokens) for tokens in tokens_por_enunciado: Calcula la longitud de cada lista de tokens en tokens_por_enunciado.\n",
        "# sum(...): Suma todas las longitudes de las listas de tokens para obtener el total de tokens.\n",
        "total_tokens = sum(len(tokens) for tokens in tokens_por_enunciado)\n",
        "\n",
        "# Imprimir el total de tokens\n",
        "print('Tokens totales:', total_tokens)"
      ],
      "metadata": {
        "id": "DZs_etmiV-fd",
        "outputId": "7f24fb30-9e78-4db4-8770-612ec60555b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens totales: 10846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 15.**  \n",
        "\n",
        "Finalmente, en este ejercicio definiremos nuestro conjunto de palabras \"stopwords\", las cuales deberás eliminar de todo el corpus.\n",
        "\n",
        "Recuerda que ejemplos de stopwords son artículos, adverbios, conectivos, etcétera, que tienen frecuencias de aparición muy altas en cualquier documento, pero que no brindan mucho significado en cuanto al significado de un enunciado.\n",
        "\n",
        "Con base a la lista de stopwords que se te proporciona, realiza un proceso de limpieza eliminando todas estas palabras del corpus obtenido en el ejercicio anterior.\n",
        "\n",
        "Obtener cuántos tokens/palabras quedan finalmente en todo el corpus.\n",
        "\n",
        "Obtener cuántos de estos tokens/palabras son diferentes, es decir, cuántos tokens únicos tendrá lo que llamaremos más adelante nuestro vocabulario."
      ],
      "metadata": {
        "id": "EFeu0OJ7WDPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Considera la siguiente lista como tu conjunto de stopwords:\n",
        "mis_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'll']"
      ],
      "metadata": {
        "id": "6FP4FF3KXGxm"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminación de stop words\n",
        "# Filtra los tokens que no están en la lista de stop words, convirtiendo primero el token a minúsculas para una comparación insensible a mayúsculas y minúsculas.\n",
        "tokens_sin_stopwords = [[token for token in tokens if token.lower() not in mis_stopwords] for tokens in tokens_por_enunciado]\n",
        "\n",
        "# Imprimir los tokens sin stop words\n",
        "for lista in tokens_sin_stopwords[:10]:\n",
        "    print(lista)\n",
        "\n"
      ],
      "metadata": {
        "id": "CD8yjyq1ZrwY",
        "outputId": "7d8f3f6b-cf95-4e8a-f14d-36a32261950f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['wow', 'loved', 'place']\n",
            "['crust', 'not', 'good']\n",
            "['not', 'tasty', 'texture', 'nasty']\n",
            "['stopped', 'late', 'may', 'bank', 'holiday', 'off', 'rick', 'steve', 'recommendation', 'loved']\n",
            "['selection', 'menu', 'great', 'prices']\n",
            "['getting', 'angry', 'want', 'damn', 'pho']\n",
            "['honeslty', 'didnt', 'taste', 'fresh']\n",
            "['potatoes', 'like', 'rubber', 'could', 'tell', 'made', 'ahead', 'time', 'kept', 'warmer']\n",
            "['fries', 'great']\n",
            "['great', 'touch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cálculo del total de tokens en el corpus después de eliminar las stop words\n",
        "\n",
        "# tokens_sin_stopwords: Lista de listas que contiene los tokens de cada comentario después de eliminar las stop words.\n",
        "total_tokens = sum(len(tokens) for tokens in tokens_sin_stopwords)\n",
        "\n",
        "# Imprimir el total de tokens en el corpus después de eliminar las stop words\n",
        "print('Tokens totales sin stop words:', total_tokens)\n"
      ],
      "metadata": {
        "id": "4ZPi5prKZro5",
        "outputId": "cfcc9bd5-fd45-4483-950b-6358331b6fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens totales sin stop words: 5846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Comentarios**\n",
        "\n",
        "Incluye finalmente tus comentarios de la actividad."
      ],
      "metadata": {
        "id": "NDbKkuxRbLoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comentarios  finales**\n",
        "\n",
        "\n",
        "En conclusión, las expresiones regulares, aunque poderosas, pueden resultar difíciles de depurar y desarrollar. Si bien ofrecen una forma eficaz de buscar y manipular patrones de texto, su complejidad puede dificultar el proceso de depuración y desarrollo, y si no se tiene cuidado pueden eliminar o introducuir resultados no deseados en el texto procesado. Si se tiene en cuenta que en la mayoria de los casos los modelos de NLP emplean grandes cantidaded de texto, los resultados pueden verse afectados de manera muy negativa. Por lo que es fundamental combinar el procesamiento de texto con técnicas de limpieza para validar los datos antes de alimentar modelos de NLP. Además, es posible integrar software de extracción, transformación y carga (ETL) para obtener los datos de manera más inmediata y de diversas fuentes.\n",
        "\n",
        "Dado que los datos suelen ser no estructurados, tanto la limpieza de los datos como el preprocesamientos mismos deben realizarse con sumo cuidado. Por ejemplo, la selección de stop words puede tener un impacto significativo en los resultados de los modelos. por lo que se requiere tener una idea muy clara de cual sera el destino de los datos procesados.\n",
        "\n"
      ],
      "metadata": {
        "id": "o7fzbvqVbUGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Referencias**\n",
        "\n",
        "Dib, F. (n.d.). regex101: build, test, and debug regex. Regex101.\n",
        "https://regex101.com/\n",
        "\n",
        "Toarca, S. (n.d.). Debuggex: Online visual regex tester. JavaScript, Python, and PCRE. https://www.debuggex.com/\n",
        "\n",
        "re — Operaciones con expresiones regulares. (n.d.). Python Documentation. https://docs.python.org/es/3/library/re.html"
      ],
      "metadata": {
        "id": "J8hwDGO089rX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fin de la Actividad de la semana 2.**"
      ],
      "metadata": {
        "id": "PHaKw_6Ldbaf"
      }
    }
  ]
}