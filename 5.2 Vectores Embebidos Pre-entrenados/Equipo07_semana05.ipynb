{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Evidence 3](https://i.imgur.com/mu6ZuGT.jpg)\n",
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## Curso: **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## Actividad Semana 5\n",
        "\n",
        "### **Vectores Embebidos Pre-entrenados: Fasttext**"
      ],
      "metadata": {
        "id": "lNl8G3vHkPSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Nombres y matrículas de los integrantes del equipo:**\n",
        "\n",
        "\n",
        "\n",
        "*   **Julio Baltazar Colín: A01794476**\n",
        "*   Elemento de lista\n",
        "\n"
      ],
      "metadata": {
        "id": "U69mHA6i201G"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCL2p6MA8NuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b7351e-bc3b-4a27-d78b-611254cdbac4"
      },
      "source": [
        "# Aquí deberás incluir todas las librerías que requieras durante esta actividad:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Instalar el paquete contractions\n",
        "!pip install contractions\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import contractions\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Pregunta - 1:**\n",
        "\n"
      ],
      "metadata": {
        "id": "4c34ZOnna3Gu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descarga los 3 archivos de Canvas y genera un nuevo DataFrame de Pandas con ellos.\n",
        "\n",
        "**Llama simplemente \"df\" a dicho DataFrame.**\n",
        "\n",
        "Los archivos los encuentras en Canvas: amazon5.txt, imdb5.txt, yelp5.txt.\n",
        "\n"
      ],
      "metadata": {
        "id": "yeNllxRdmeWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#carga de datos desde un repositorio externo:\n",
        "\n",
        "import requests\n",
        "urlAmzn = 'https://raw.githubusercontent.com/Julio21-ai/NLP-GPO10/main/5.2%20Vectores%20Embebidos%20Pre-entrenados/amazon5.txt'\n",
        "urlimdb = 'https://raw.githubusercontent.com/Julio21-ai/NLP-GPO10/main/5.2%20Vectores%20Embebidos%20Pre-entrenados/imdb5.txt'\n",
        "urlyelp = 'https://raw.githubusercontent.com/Julio21-ai/NLP-GPO10/main/3.2%20Actividad%202/yelp_labelled.txt'\n",
        "\n",
        "responce_amzn = requests.get(urlAmzn)\n",
        "responce_imdb = requests.get(urlimdb)\n",
        "responce_urlyelp = requests.get(urlyelp)\n",
        "\n",
        "data_amzn = None\n",
        "data_imdb= None\n",
        "data_urlyelp= None\n",
        "\n",
        "if responce_amzn.status_code == 200: #200 = OK\n",
        "    data_amzn = responce_amzn.text\n",
        "else:\n",
        "    print(\"Error al obtener el archivo:\", responce_amzn.status_code)\n",
        "\n",
        "if responce_imdb.status_code == 200: #200 = OK\n",
        "    data_imdb = responce_imdb.text\n",
        "else:\n",
        "    print(\"Error al obtener el archivo:\", responce_imdb.status_code)\n",
        "\n",
        "if responce_urlyelp.status_code == 200: #200 = OK\n",
        "    data_urlyelp = responce_urlyelp.text\n",
        "else:\n",
        "    print(\"Error al obtener el archivo:\", responce_imdb.status_code)\n"
      ],
      "metadata": {
        "id": "g7esxl5yLN_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "from io import StringIO\n",
        "\n",
        "dfa = pd.read_csv(StringIO(data_amzn), sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "dfi = pd.read_csv(StringIO(data_imdb), sep=r'\\s{3,}', names=['review','label'], header=None, encoding='utf-8')\n",
        "dfy = pd.read_csv(StringIO(data_urlyelp), sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "\n",
        "print('Total de registros de Amazon:',dfa.shape)\n",
        "print('Total de registros de IMBD:',dfi.shape)\n",
        "print('Total de registros de Yelp:',dfy.shape)\n",
        "\n",
        "df = pd.concat([dfa, dfi, dfy], ignore_index=True)\n",
        "df['label'] = pd.to_numeric(df['label'])\n",
        "\n",
        "print('Total de registros dataframe df:',df.shape)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ],
      "metadata": {
        "id": "T_lyEFRkxzC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5324214c-94cf-4ff1-d378-f969e0e7cacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de registros de Amazon: (1000, 2)\n",
            "Total de registros de IMBD: (1000, 2)\n",
            "Total de registros de Yelp: (1000, 2)\n",
            "Total de registros dataframe df: (3000, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c6ff799b6a37>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  dfi = pd.read_csv(StringIO(data_imdb), sep=r'\\s{3,}', names=['review','label'], header=None, encoding='utf-8')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifiquemos la información del DataFrame:\n",
        "df.info()"
      ],
      "metadata": {
        "id": "3-w1xMLYnm9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f84ba1b-65e1-452c-ff3f-f19107b58055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   review  3000 non-null   object\n",
            " 1   label   3000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 47.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Y veamos sus primeros registros:\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NfVUcYe1nubT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b224967a-ce1f-457c-d193-3e6c56689270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d3284fb-48f1-46f7-af86-4b3709f2ee7a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d3284fb-48f1-46f7-af86-4b3709f2ee7a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d3284fb-48f1-46f7-af86-4b3709f2ee7a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d3284fb-48f1-46f7-af86-4b3709f2ee7a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc895b9e-bbf6-48bc-9154-cec632295063\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc895b9e-bbf6-48bc-9154-cec632295063')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc895b9e-bbf6-48bc-9154-cec632295063 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2982,\n        \"samples\": [\n          \"We've tried to like this place but after 10+ times I think we're done with them.\",\n          \"The best example of how dumb the writing is when it's established that you can turn the zombie-students back into humans by removing a necklace containing a piece of the meteorite.\",\n          \"It was that loud.Glad to say that the Plantronics 510 maintains a flawless connection to my cell and with no static during normal use.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Pregunta - 2:**"
      ],
      "metadata": {
        "id": "MfZZ0stLmWJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realiza el proceso de limpieza.\n",
        "\n",
        "Aplica el preprocesamiento que consideres adecuado, sin embargo, deberás aplicar necesariamente alguna de las técnicas de lematización.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7F6JF5BommZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "def remover_espacios_extra(texto):\n",
        "    # Eliminar los espacios iniciales y finales y dividir el texto por espacios\n",
        "    texto_filtrado = re.sub(r'\\s+', ' ', texto).strip().split()\n",
        "    # texto_filtrado las palabras con un solo espacio\n",
        "    retval = ' '.join(texto_filtrado)\n",
        "    return retval\n",
        "\n",
        "def procesar_comilla(texto):\n",
        "    texto_filtrado = texto\n",
        "    # Eliminar terminaciones 's\n",
        "    texto_filtrado = re.sub(r\"'s\\b\", '', texto_filtrado)\n",
        "    # Reemplazar \".\", \",\" , \":\", y \"_\" por espacios en blanco\n",
        "    texto_filtrado = re.sub(r\"\\'\", ' ', texto_filtrado)\n",
        "    return texto_filtrado\n",
        "\n",
        "def eliminar_no_alfa(texto):\n",
        "    texto_filtrado = texto\n",
        "\n",
        "    # Eliminar caracteres no alfanuméricos, excepto \".\", \",\", \":\", \"-\" y \"_\"\n",
        "    texto_filtrado = re.sub(r\"[^\\w\\s\\.,:-]+\", '', texto_filtrado)\n",
        "\n",
        "    # Eliminar guiones repetidos en medio de la cadena\n",
        "    texto_filtrado = re.sub(r'(?<!-)-{2,}(?!-)', ' ', texto_filtrado)\n",
        "\n",
        "    # Eliminar guiones al principio y al final de la cadena\n",
        "    texto_filtrado = re.sub(r'^-+|-+$', '', texto_filtrado)\n",
        "\n",
        "    # Reemplazar \".\", \",\" , \":\", y \"_\" por espacios en blanco\n",
        "    texto_filtrado = re.sub(r'[\\.,:_]', ' ', texto_filtrado)\n",
        "\n",
        "    return texto_filtrado\n",
        "\n",
        "def minusculas(texto):\n",
        "    #Convertir a minusculas\n",
        "    return texto.lower()\n",
        "\n",
        "def remover_caracteres_sueltos(texto):\n",
        "    # Expresión regular para encontrar caracteres sueltos\n",
        "    expresion_regular = r'\\b\\w{1}\\b'  # Coincidirá con cualquier carácter único\n",
        "\n",
        "    # Reemplaza los caracteres sueltos con una cadena vacía\n",
        "    texto_filtrado = re.sub(expresion_regular, '', texto)\n",
        "\n",
        "    return texto_filtrado\n",
        "\n",
        "def eliminar_no_ascii(texto):\n",
        "    # Eliminar caracteres no ASCII\n",
        "    retval = re.sub(r'[^\\x00-\\x7F]+', '', texto)\n",
        "    return  texto\n",
        "\n",
        "def eliminar_digitos(texto):\n",
        "    # Utilizar una expresión regular para eliminar palabras con dígitos\n",
        "    texto_filtrado = re.sub(r'\\b\\w*\\d\\w*\\b', '', texto)\n",
        "\n",
        "    # Eliminar espacios adicionales resultantes\n",
        "    #texto_filtrado = re.sub(r'\\s+', ' ', texto_filtrado).strip()\n",
        "\n",
        "    return texto_filtrado\n",
        "\n",
        "\n",
        "def expandir_contracciones(texto):\n",
        "    # Expandir contracciones\n",
        "    return contractions.fix(texto)\n",
        "\n",
        "\n",
        "def lematizado(texto):\n",
        "    wnl = WordNetLemmatizer()\n",
        "    # Tokenizar el texto en palabras\n",
        "    palabras = word_tokenize(texto)\n",
        "\n",
        "    palabras_lemmatizadas = []\n",
        "    for palabra in palabras:\n",
        "        # Lemmatizar la palabra como adjetivo\n",
        "        lemmatizada = wnl.lemmatize(palabra, 'a')\n",
        "        # Lemmatizar la palabra como verbo\n",
        "        lemmatizada = wnl.lemmatize(lemmatizada, 'v')\n",
        "        # Lemmatizar la palabra como sustantivo\n",
        "        lemmatizada = wnl.lemmatize(lemmatizada, 'n')\n",
        "        # Lemmatizar la palabra como adverbio\n",
        "        lemmatizada = wnl.lemmatize(lemmatizada, 'r')\n",
        "        palabras_lemmatizadas.append(lemmatizada)\n",
        "\n",
        "    # Unir las palabras lemmatizadas en un texto de nuevo\n",
        "    texto_filtrado = ' '.join(palabras_lemmatizadas)\n",
        "\n",
        "    return texto_filtrado\n",
        "\n",
        "def remove_stop_words(lista_palabras, stopwords):\n",
        "    #Eliminar las stopwords\n",
        "    palabras_sin_stopwords = [palabra for palabra in lista_palabras if palabra not in stopwords]\n",
        "    return palabras_sin_stopwords\n",
        "\n",
        "\n",
        "def tokenizar(enunciado):\n",
        "    # Tokenizar el texto\n",
        "    tokens = word_tokenize(enunciado)\n",
        "    # Eliminar caracteres no alfanuméricos\n",
        "    tokens = [token for token in tokens if token.isalnum()]\n",
        "    return tokens\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "  texto_filtrado = texto\n",
        "  texto_filtrado = expandir_contracciones(texto_filtrado)\n",
        "  texto_filtrado = procesar_comilla(texto_filtrado)\n",
        "  texto_filtrado = eliminar_no_alfa(texto_filtrado)\n",
        "  texto_filtrado = eliminar_no_ascii(texto_filtrado)\n",
        "  texto_filtrado = eliminar_digitos(texto_filtrado)\n",
        "  texto_filtrado = remover_espacios_extra(texto_filtrado)\n",
        "  texto_filtrado = lematizado(texto_filtrado)\n",
        "  texto_filtrado = remover_caracteres_sueltos(texto_filtrado)\n",
        "  texto_filtrado = minusculas(texto_filtrado)\n",
        "  return texto_filtrado\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n"
      ],
      "metadata": {
        "id": "6qfe7J18NpNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "X = df.review     # Serie de strings\n",
        "Y = df.label      # Serie de enteros 0s y 1s\n",
        "\n",
        "\n",
        "texto_limpio = X.apply(limpiar_texto)\n",
        "df['review'].to_csv('rsultado_sucio.txt', index=False)\n",
        "texto_limpio.to_csv('resultado_limpio.txt', index=False)\n",
        "\n",
        "tokens_list = [tokenizar(texto) for texto in texto_limpio]\n",
        "Xclean = tokens_list\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ],
      "metadata": {
        "id": "TsnvMp-7oYCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Despleguemos los primeros comentarios después de tu proceso de limpieza:\n",
        "\n",
        "for x in Xclean[0:5]:\n",
        "  print(x)\n"
      ],
      "metadata": {
        "id": "7jlQuoI2o33T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acab8f7e-7430-44be-ab3f-e1e4ab0d275c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['so', 'there', 'be', 'no', 'way', 'for', 'me', 'to', 'plug', 'it', 'in', 'here', 'in', 'the', 'us', 'unless', 'go', 'by', 'converter']\n",
            "['good', 'case', 'excellent', 'value']\n",
            "['great', 'for', 'the', 'jawbone']\n",
            "['tied', 'to', 'charger', 'for', 'conversation', 'last', 'more', 'than', 'minute', 'major', 'problems']\n",
            "['the', 'mic', 'be', 'great']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pregunta - 3:**\n"
      ],
      "metadata": {
        "id": "ygchEdcKqIzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Realicemos una partición aleatoria con los mismos porcentajes de la práctica pasada para poder comparar dichos resultados con los de\n",
        "esta actividad, a saber, 70%, 15% y 15%, para entrenamiento, validación y prueba, respectivamente."
      ],
      "metadata": {
        "id": "7wEIOkkl9Dot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ************* Inicia la sección de agregar código:*****************************\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(Xclean, Y, train_size=.70, shuffle=True, random_state=1)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=.50, shuffle=True, random_state=17)\n",
        "\n",
        "print('X,y Train:', len(x_train), len(y_train))      # los \"x_\" son \"list\" y los \"y_\" son \"Series\"\n",
        "print('X,y Val:', len(x_val), len(y_val))\n",
        "print('X,y Test', len(x_test), len(y_test))\n",
        "\n",
        "# *********** Termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "# verificemos las dimensiones obtenidas:\n",
        "print('X,y Train:', len(x_train), len(y_train))\n",
        "print('X,y Val:', len(x_val), len(y_val))\n",
        "print('X,y Test', len(x_test), len(y_test))"
      ],
      "metadata": {
        "id": "b0SAcYdq9X0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20542868-188a-4e2f-86ce-014773176a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X,y Train: 2100 2100\n",
            "X,y Val: 450 450\n",
            "X,y Test 450 450\n",
            "X,y Train: 2100 2100\n",
            "X,y Val: 450 450\n",
            "X,y Test 450 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pregunta - 4:**"
      ],
      "metadata": {
        "id": "1qjKoEqiqBN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Construye tu vocabulario a continuación\n"
      ],
      "metadata": {
        "id": "jENsKiN99r3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a.\tUsa el conjunto de entrenamiento para generar tu vocabulario\n",
        "#     con un tamaño que consideres adecuado:\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "lista_tokens = Counter()\n",
        "\n",
        "for k in range(len(x_train)):\n",
        "  lista_tokens.update(x_train[k])\n",
        "\n",
        "\n",
        "# Contar la frecuencia de cada token\n",
        "frecuencia_tokens = Counter(lista_tokens)\n",
        "\n",
        "# Definir el umbral de frecuencia\n",
        "umbral_frecuencia = 2\n",
        "\n",
        "# Filtrar palabras con frecuencia menor al umbral\n",
        "frecuencia_filtrada = {token: freq for token, freq in frecuencia_tokens.items() if freq >= umbral_frecuencia}\n",
        "\n",
        "# Ordenar palabras por frecuencia\n",
        "palabras_ordenadas = sorted(frecuencia_filtrada.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# Crear el vocabulario: un diccionario que asigna un índice único a cada token\n",
        "diccionario = {token: idx for idx, (token, _) in enumerate(palabras_ordenadas)}\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ],
      "metadata": {
        "id": "TzJntmLPqPqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b.\tIndica el tamaño del vocabulario generado.\n",
        "\n",
        "print('Longitud del vocabulario generado:')\n",
        "\n",
        "\n",
        "# ******* Inicia la sección de agregar código: ***********\n",
        "print(f\"{len(diccionario)}, palabras\")\n",
        "\n",
        "N = 10  # Número de elementos a imprimir\n",
        "print(f\"Primeros {N} elementos del diccionario:\")\n",
        "for i, (palabra, idx) in enumerate(diccionario.items()):\n",
        "    if i >= N:\n",
        "        break\n",
        "    print(f\"Token: {palabra}, Índice: {idx}\")\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ],
      "metadata": {
        "id": "yTDZ0Rr86CUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9dd124-b73b-4091-ce9f-ee223e6117f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del vocabulario generado:\n",
            "1495, palabras\n",
            "Primeros 10 elementos del diccionario:\n",
            "Token: be, Índice: 0\n",
            "Token: the, Índice: 1\n",
            "Token: and, Índice: 2\n",
            "Token: it, Índice: 3\n",
            "Token: to, Índice: 4\n",
            "Token: this, Índice: 5\n",
            "Token: not, Índice: 6\n",
            "Token: of, Índice: 7\n",
            "Token: have, Índice: 8\n",
            "Token: in, Índice: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c.\t¿Por qué debe usarse solamente el conjunto de entrenamiento para generar el vocabulario?\n",
        "\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "La principal razón para usar el conjunto de entrenamiento para generar el vocabulario es evitar el filtrado de información, lo que impide que los modelos tengan una ventaja al momento de realizar las predicciones. Esto previene el sesgo en la información y proporciona una mayor imparcialidad en el modelo.\n",
        "\n",
        "Otra razón es mantener la consistencia al emplear un único diccionario que sea común para todos los modelos, facilitando el manejo de la información y permitiendo que los datos sean reproducibles.\n",
        "\n",
        "El usar el vocabulario para el conjunto de entrenamiento tambien es mas eficiente pues permite manejar un unico conjunto de datos, en los casos donde se trabaja con modelos grandes, el costo computacional resulta menor.\n",
        "\n",
        "Por ultimo si cada conjunto manejara su propio vocabulario, seria muy dificil la convergencia de los modelos pues se tendrian varias palabras que estaria fuera del vocabulario conocido para el modelo lo que haria muy dificil su convergencia.\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n"
      ],
      "metadata": {
        "id": "NDa4EhTqrw15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# d.\tCon el vocabulario generado, filtra los conjuntos de entrenamiento,\n",
        "#     validación y prueba para que todos los comentarios usen solamente las\n",
        "#     palabras de este vocabulario.\n",
        "\n",
        "#     Llamar train_x, val_x y test_x a estos tres conjuntos.\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "train_x = []\n",
        "for ss in x_train:\n",
        "  train_x.append([w for w in ss if w in diccionario])\n",
        "\n",
        "val_x = []\n",
        "for ss in x_val:\n",
        "  val_x.append([w for w in ss if w in diccionario])\n",
        "\n",
        "test_x = []\n",
        "for ss in x_test:\n",
        "  test_x.append([w for w in ss if w in diccionario])\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ],
      "metadata": {
        "id": "7ykjxQI3rpxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vemos el resultado de los primeros comentarios del conjunto de entrenamiento:\n",
        "\n",
        "for ss in train_x[0:5]:\n",
        "  print(ss)"
      ],
      "metadata": {
        "id": "iYF2RGuPtQTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb8043f-1cc8-4339-cb0d-112abe2893c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['his', 'do', 'not', 'fare', 'much', 'good', 'with', 'people', 'like', 'morgan', 'and', 'ed', 'just', 'waste']\n",
            "['tonight', 'have', 'the', 'filet', 'special', 'and', 'it', 'suck']\n",
            "['pay', 'the', 'bill', 'but', 'do', 'not', 'tip', 'because', 'felt', 'the', 'server', 'do', 'terrible', 'job']\n",
            "['how', 'can', 'you', 'call', 'yourself', 'if', 'you', 'can', 'not', 'properly', 'cook', 'steak', 'do', 'not', 'understand']\n",
            "['however', 'the', 'keypad', 'be', 'so', 'tinny', 'that', 'sometimes', 'the', 'wrong', 'button']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pregunta - 5:**"
      ],
      "metadata": {
        "id": "RS0Hxj25vTWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "a. Incluye una tabla comparativa de pros y contras entre los modelos FastText, word2vec de Google y Glove de Stanford."
      ],
      "metadata": {
        "id": "CnHHAza5_P5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Modelo</th>\n",
        "      <th>Pros</th>\n",
        "      <th>Contras</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>FastText</td>\n",
        "      <td>\n",
        "        <ul>\n",
        "          <li>Captura información subpalabra, lo que ayuda con palabras raras y OOV (Out Of Vocabulary).</li>\n",
        "          <li>Más preciso en lenguajes morfológicamente ricos.</li>\n",
        "          <li>Capaz de manejar palabras compuestas y errores tipográficos.</li>\n",
        "          <li> Captura mejor la relación entre palabras similares por morfología.</li>\n",
        "          <li>Open source.</li>\n",
        "          <li>Disponible en varios idiomas.</li>          \n",
        "        </ul>\n",
        "      </td>\n",
        "      <td>\n",
        "        <ul>\n",
        "          <li>Generalmente más lento de entrenar comparado con Word2Vec.</li>\n",
        "          <li>Requiere más espacio de almacenamiento debido a la información de subpalabra.</li>\n",
        "        </ul>\n",
        "      </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Word2Vec (Google)</td>\n",
        "      <td>\n",
        "        <ul>\n",
        "          <li>Muy eficiente y rápido de entrenar.</li>\n",
        "          <li>Genera vectores de alta calidad que capturan relaciones semánticas.</li>\n",
        "          <li>Disponible en muchas implementaciones y bibliotecas.</li>\n",
        "        </ul>\n",
        "      </td>\n",
        "      <td>\n",
        "        <ul>\n",
        "          <li>No maneja palabras raras o OOV sin renentrenar.</li>\n",
        "          <li>No captura información subpalabra.</li>\n",
        "          <li>Trata las palabras como unidades atomicas por lo que en ocaciones pude perder el contexto.</li>\n",
        "          <li>Version opensource reducida, versiones comerciales bajo licencia.</li>\n",
        "        </ul>\n",
        "      </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>GloVe (Stanford)</td>\n",
        "      <td>\n",
        "        <ul>\n",
        "          <li>Basado en estadísticas globales, lo que puede capturar información de contexto mejor.</li>\n",
        "          <li>Genera vectores que pueden ser más precisos para ciertas tareas NLP.</li>\n",
        "          <li>Muy eficiente para preentrenar en grandes corpus.</li>\n",
        "        </ul>\n",
        "      </td>\n",
        "      <td>\n",
        "        <ul>\n",
        "          <li>Generalmente más lento de entrenar comparado con Word2Vec.</li>\n",
        "          <li>El rendimiento puede no ser tan bueno en corpus más pequeños.</li>\n",
        "          <li>Entrenamiento más complejo y puede ser más lento que Word2Vec.</li>\n",
        "          <li>Requiere una cantidad significativa de memoria y almacenamiento.</li>\n",
        "        </ul>\n",
        "      </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n"
      ],
      "metadata": {
        "id": "uTI9xSgF_Xc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pregunta - 6:**\n",
        "\n",
        "Utiliza el modelo FastText de vectores embebidos pre-entrenados de dimensión 300 para generar un nuevo diccionario clave-valor, donde la “clave” será cada token o palabra de tu vocabulario y el “valor” será su vector embebido de dimensión 300.\n",
        "\n",
        "Este diccionario deberá ser del mismo tamaño que el vocabulario previo que hayas construido previamente.\n",
        "\n",
        "Es recomendable que una vez que generes el nuevo vocabulario de vectores embebidos, guardes dicho diccionario en un archivo.\n",
        "\n",
        "Recuerda borrar la variable donde descargaste los 2 millones de vectores embebidos Fasttext.\n",
        "\n"
      ],
      "metadata": {
        "id": "ToqRl7fT_fn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "fasttext.util.download_model('en',if_exists='ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "jSGDj-XLY2h0",
        "outputId": "91c9129d-a9fb-4721-d582-7cd95bbfec7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cc.en.300.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "ft = fasttext.load_model('cc.en.300.bin')\n",
        "vocab_embedings = {}\n",
        "\n",
        "for token,idx in diccionario.items():\n",
        "  vector = ft.get_word_vector(token)\n",
        "  vocab_embedings[token] = vector\n",
        "\n",
        "del ft\n",
        "\n",
        "# Guardar el diccionario en un archivo\n",
        "with open('vocabulario_fasttext.pkl', 'wb') as f:\n",
        "    pickle.dump(vocab_embedings, f)\n",
        "\n",
        "# Confirmar que se ha guardado\n",
        "print(\"Diccionario guardado en 'vocabulario_fasttext.pkl'\")\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ],
      "metadata": {
        "id": "UdK-jMfLxHLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa22147-413e-4120-cc80-bf7613d6bdff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diccionario guardado en 'vocabulario_fasttext.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el diccionario desde el archivo\n",
        "with open('vocabulario_fasttext.pkl', 'rb') as f:\n",
        "    vocab_embedings = pickle.load(f)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mJ4RK9GwcDpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imprimir los primeros N elementos del diccionario\n",
        "N = 1  # Número de elementos a imprimir\n",
        "print(f\"\\nPrimeros {N} elementos del diccionario:\")\n",
        "for i, (token, c) in enumerate(vocab_embedings.items()):\n",
        "    if i >= N:\n",
        "        break\n",
        "    print(f\"Token: {token}, vector: {c}\")\n",
        "    print(f\"vector sz {len(c)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_aXJixXYuHO",
        "outputId": "96edc04b-c530-41a4-c20c-1ba990153b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primeros 1 elementos del diccionario:\n",
            "Token: be, vector: [-9.63205993e-02 -8.19036737e-02 -4.77219410e-02  1.46949440e-01\n",
            " -2.23413676e-01 -8.14826041e-02 -2.62784898e-01 -9.18371975e-03\n",
            "  9.39049870e-02 -8.82623310e-04 -1.31746689e-02 -8.48824829e-02\n",
            " -5.35654761e-02 -6.28753332e-03 -1.85673028e-01  2.29752824e-01\n",
            "  4.28092778e-02  4.56203744e-02 -2.81269066e-02  5.51726639e-01\n",
            " -7.04716146e-02  5.79598658e-02  3.89252491e-02 -3.09593510e-03\n",
            "  1.17756665e-01 -1.82199806e-01  6.86402097e-02  3.97641845e-02\n",
            " -1.04433924e-01  3.45441222e-01 -5.88678569e-03 -8.50912184e-02\n",
            "  6.21016659e-02  2.97347546e-01  2.68255733e-02  3.01602781e-02\n",
            " -1.00006558e-01 -1.55223802e-01 -1.22539923e-01  6.37540175e-03\n",
            " -1.39430225e-01  6.34008273e-02 -2.51493216e-01  5.28848097e-02\n",
            "  1.95040017e-01 -1.30737111e-01 -5.72192073e-02  2.75106847e-01\n",
            "  1.09033130e-01 -9.26046371e-02 -5.19613810e-02 -6.83219405e-03\n",
            " -8.30914751e-02 -1.54212385e-01 -1.24819856e-02  1.38309076e-01\n",
            " -3.80693078e-02 -3.24041903e-01 -1.23284131e-01 -1.90022495e-02\n",
            " -1.86634570e-01 -2.31010690e-02 -2.44914088e-02 -4.93953049e-01\n",
            " -3.33141267e-01 -1.07483137e-02  2.63709668e-02  2.59032100e-02\n",
            "  1.36826232e-01 -1.79619208e-01 -2.39304617e-01  4.50918829e-04\n",
            "  1.22396551e-01 -1.62431840e-02  4.23442759e-02 -6.85016960e-02\n",
            "  8.40329900e-02  1.10009342e-01 -3.18531096e-01 -2.50793844e-01\n",
            "  8.59959573e-02  3.20231877e-02  4.02980968e-02  9.10009295e-02\n",
            "  4.26493913e-01 -6.65172585e-04  3.16566736e-01  2.70164255e-02\n",
            "  1.83051735e-01 -2.46244863e-01 -2.01383099e-01 -8.02942365e-02\n",
            "  4.00959402e-01 -7.66836181e-02 -2.81336606e-01 -6.04517795e-02\n",
            " -7.37982452e-01  6.94737583e-02 -4.18652147e-02 -1.38625860e-01\n",
            " -1.22223638e-01  6.55062944e-02  7.85972401e-02 -4.46987331e-01\n",
            " -4.35412452e-02  7.99130574e-02 -9.47604552e-02  5.72302416e-02\n",
            " -9.02177393e-02  5.63343167e-02 -7.66895786e-02 -2.06849575e-02\n",
            "  2.49141473e-02 -4.40057099e-01  5.55944687e-04 -6.95855170e-02\n",
            " -1.05536729e-02 -2.22762115e-02 -4.39201631e-02 -1.04698971e-01\n",
            "  2.19153926e-01 -1.19940095e-01 -2.46419478e-02 -4.80533391e-02\n",
            "  1.99027807e-02  3.57523374e-02 -1.05371818e-01 -2.81973124e-01\n",
            " -6.77816868e-02  1.40293106e-01 -5.45124188e-02 -9.97450724e-02\n",
            "  2.41627112e-01  3.17222655e-01  1.10882089e-01  5.24552725e-02\n",
            " -7.00941086e-01 -1.62079722e-01  1.27017409e-01  2.22769514e-01\n",
            "  9.20921266e-02 -8.55954513e-02 -7.20387474e-02 -2.94909924e-02\n",
            "  1.77114457e-01 -9.73206386e-02 -7.78731823e-01  4.44993190e-02\n",
            " -1.77367143e-02 -6.68642670e-02 -5.61715901e-01  1.18722223e-01\n",
            "  9.84588861e-02 -2.55960599e-02  3.91452052e-02  5.10312431e-02\n",
            " -1.60945728e-02  6.37393445e-02  1.49682149e-01  1.24990880e-01\n",
            "  9.78447124e-02  1.02976091e-01  2.10996985e-01  1.77311078e-02\n",
            " -1.43588027e-02 -7.27392137e-02  6.27250448e-02 -1.28911346e-01\n",
            " -1.20736115e-01 -6.32887706e-02  8.29670951e-02 -2.06931736e-02\n",
            "  1.02994308e-01  7.55577395e-03  1.47905219e-02 -1.03228360e-01\n",
            " -6.56743571e-02 -3.48501444e-01  1.92311330e-04 -9.92326662e-02\n",
            "  1.01853743e-01  5.91604374e-02 -9.41614136e-02 -2.82357037e-01\n",
            "  1.16559163e-01 -4.94002923e-03 -2.68225819e-01  2.49889512e-02\n",
            "  3.24043483e-02  6.55694082e-02  7.63572147e-03  1.04625477e-02\n",
            " -3.47596556e-02 -8.88505057e-02  1.10966831e-01  8.67631137e-02\n",
            "  2.10709661e-01 -4.79846857e-02 -4.88156527e-02  2.51020223e-01\n",
            " -1.04625158e-01  5.77387154e-01 -4.36750874e-02 -1.52983680e-01\n",
            "  1.46948338e-01  7.00819567e-02 -3.20403993e-01 -6.44616261e-02\n",
            " -7.48921931e-02 -4.75020766e-01  3.00843138e-02 -9.10851657e-02\n",
            " -2.93542147e-01  8.75747129e-02  2.14364111e-01 -9.70429331e-02\n",
            "  1.20241173e-01 -1.04180118e-02  1.63881220e-02 -2.02897504e-01\n",
            "  1.54698789e-02  5.32802641e-02  1.83257326e-01  4.50537801e-01\n",
            " -1.83381945e-01  1.42654389e-01  4.40880023e-02  8.48970786e-02\n",
            " -8.17850158e-02 -2.88781170e-02  1.33027427e-03  9.41598266e-02\n",
            " -6.57823011e-02 -1.41397059e-01  8.91428292e-02 -3.44216913e-01\n",
            "  3.68152671e-02 -1.49176463e-01  1.95154417e-02  4.71846014e-02\n",
            " -5.18022291e-02 -2.33758330e-01  3.03735137e-01 -2.82348216e-01\n",
            "  1.29601192e+00 -7.00819716e-02  2.13343650e-02  4.39951196e-02\n",
            " -2.61527091e-01  1.38305038e-01  1.55430555e-01  3.38243335e-01\n",
            "  6.76803961e-02 -9.56759378e-02  2.48808227e-02  1.06018364e-01\n",
            " -7.14262649e-02 -1.96022943e-01  2.86138188e-02  5.92969060e-02\n",
            "  9.11269784e-02  6.92954004e-01 -3.30283232e-02  9.04530734e-02\n",
            " -2.76369601e-01 -9.83833075e-02  1.91144839e-01  1.28658280e-01\n",
            "  1.75651193e-01 -6.92908540e-02 -2.02576399e-01 -2.67903745e-01\n",
            "  3.38913202e-02  4.69832003e-01 -4.39291224e-02 -2.08551884e-01\n",
            " -3.28292578e-01  1.95285216e-01  2.04647407e-01  1.34758666e-01\n",
            " -7.17819035e-02 -3.05647217e-03 -5.27054727e-01 -1.15171634e-01\n",
            "  2.03583166e-02 -1.77175954e-01  1.42800570e-01 -8.98597911e-02\n",
            " -9.02722254e-02 -4.30769734e-02 -1.21275783e-01 -1.44385770e-01\n",
            " -3.00109386e-01 -9.24868137e-02  1.50355190e-01  1.10603496e-02\n",
            "  1.68124944e-01  3.52441639e-01 -1.47835642e-01  3.28701623e-02]\n",
            "vector sz 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pregunta - 7:**"
      ],
      "metadata": {
        "id": "W4S7q0yR0Mpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Generamos los vectores embebidos a paertir de los conjuntos de entrenamiento, validación y preuba.\n",
        "\n",
        "Los llamaremos trainEmb, valEmb y testEmb, respectivamente."
      ],
      "metadata": {
        "id": "VyeOrkoaC1eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "def tokens_a_embedding(lista_tokens, vocab_embeddings):\n",
        "    vectores_palabras = [vocab_embeddings[token] for token in lista_tokens if token in vocab_embeddings]\n",
        "    if vectores_palabras:\n",
        "        return np.mean(vectores_palabras, axis=0)\n",
        "    else:\n",
        "        return np.zeros(300)  # Dimensión de los embeddings de FastText\n",
        "\n",
        "# Convertir los enunciados en embeddings\n",
        "def generar_embedings(sentences, vocab_embeddings):\n",
        "    return np.array([tokens_a_embedding(lista_tokens, vocab_embeddings) for lista_tokens in sentences])\n",
        "\n",
        "\n",
        "# Generar los embeddings para cada conjunto de datos\n",
        "trainEmb =generar_embedings(x_train, vocab_embedings)\n",
        "valEmb = generar_embedings(x_val, vocab_embedings)\n",
        "testEmb = generar_embedings(x_test, vocab_embedings)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ],
      "metadata": {
        "id": "wnfQpkxg0Usq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos las dimensiones de cada conjunto embebido:\n",
        "\n",
        "print(\"Train-Emb:\", trainEmb.shape)\n",
        "print(\"Val-Emb:\", valEmb.shape)\n",
        "print(\"Test-Emb:\", testEmb.shape)"
      ],
      "metadata": {
        "id": "J3BBF96D0N8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5fe9f93-82e3-435d-ff12-079e8be0ddd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-Emb: (2100, 300)\n",
            "Val-Emb: (450, 300)\n",
            "Test-Emb: (450, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pregunta - 8:**\n"
      ],
      "metadata": {
        "id": "pibp1LA91CP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Utiliza los modelos de regresión logística y bosque aleatorio (random forest) y encuentra sus desempeños.\n",
        "\n",
        "Compara los resultados con los de la semana anterior."
      ],
      "metadata": {
        "id": "UxC9K0VnGOwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Busqueda de hiperparametros para obtener un mejor modelo:\n",
        "from scipy.stats import loguniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "#Hiperparámetros para Regresión Logística\n",
        "hiperparametros_LR = {\n",
        "    'C': loguniform(1e-5, 100),\n",
        "    'penalty': [ None, 'l2',],\n",
        "    'solver':  ['newton-cg', 'lbfgs', 'liblinear'],\n",
        "    'max_iter': [1000]\n",
        "}\n",
        "\n",
        "#Inicializar modelos\n",
        "modelo_LR = LogisticRegression()\n",
        "\n",
        "\n",
        "#Inicializar búsqueda de cuadrícula para cada modelo con sus respectivos hiperparámetros\n",
        "busqueda_LR = RandomizedSearchCV(modelo_LR, hiperparametros_LR, n_iter=500, random_state=248, n_jobs=-1 ,cv=5)\n",
        "\n",
        "#Ajustar búsqueda de cuadrícula a los datos\n",
        "busqueda_LR.fit(trainEmb, y_train)\n",
        "\n",
        "\n",
        "#Obtener los mejores hiperparámetros para cada modelo\n",
        "mejores_hiperparametros_LR = busqueda_LR.best_params_\n",
        "\n",
        "print(\"Mejores hiperparámetros para Regresión Logística:\", mejores_hiperparametros_LR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAef8MmyeK-6",
        "outputId": "aa1964cf-f358-4345-8be2-39dc1fb27bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "425 fits failed out of a total of 2500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "425 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
            "    raise ValueError(\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.78619048 0.50857143 0.79619048 0.79619048 0.79285714 0.50857143\n",
            " 0.79619048 0.80238095 0.77857143 0.79619048 0.82285714        nan\n",
            " 0.7847619  0.79619048 0.62142857 0.79619048 0.51285714 0.79285714\n",
            " 0.82       0.58619048 0.79619048 0.82190476 0.81904762 0.82095238\n",
            " 0.80666667 0.50857143 0.80857143        nan        nan 0.79619048\n",
            " 0.79619048 0.79619048 0.50857143 0.79619048 0.79619048 0.50857143\n",
            " 0.50857143 0.50857143 0.50857143 0.79619048 0.79619048 0.74047619\n",
            " 0.79619048 0.50857143 0.50857143 0.50857143 0.79619048 0.79619048\n",
            " 0.50857143 0.79       0.79619048 0.79619048 0.79       0.79619048\n",
            " 0.79619048 0.79619048        nan 0.78571429 0.79619048 0.68714286\n",
            " 0.79619048 0.79619048        nan        nan 0.79619048 0.52142857\n",
            " 0.79142857 0.79619048 0.79619048 0.5552381  0.79619048 0.79619048\n",
            " 0.79619048 0.79619048 0.53428571        nan        nan 0.50857143\n",
            "        nan        nan 0.67428571        nan 0.79619048 0.79619048\n",
            "        nan 0.79619048 0.79619048 0.70857143 0.79619048 0.82333333\n",
            " 0.5347619  0.79619048 0.79619048        nan 0.74904762 0.50857143\n",
            " 0.50857143 0.56380952 0.82142857 0.78428571 0.50857143 0.79619048\n",
            " 0.79619048 0.79619048 0.57714286 0.80761905 0.81333333 0.79047619\n",
            " 0.74095238 0.82190476 0.81333333 0.79619048 0.79619048        nan\n",
            " 0.68       0.70428571 0.79619048 0.50857143 0.81857143 0.79619048\n",
            " 0.79619048 0.70619048 0.82142857        nan 0.79619048 0.82047619\n",
            " 0.50857143 0.50857143 0.79619048 0.79619048 0.53619048 0.79619048\n",
            "        nan 0.79619048 0.79619048        nan 0.68761905 0.79619048\n",
            "        nan        nan 0.65904762 0.74809524 0.79619048 0.56285714\n",
            " 0.50857143 0.50857143        nan 0.51       0.70857143 0.50857143\n",
            " 0.79619048 0.79619048 0.82190476 0.50857143 0.79047619 0.73571429\n",
            " 0.50857143 0.50857143 0.58666667 0.70095238 0.80428571 0.79619048\n",
            "        nan 0.53428571        nan        nan 0.79619048 0.79619048\n",
            " 0.79619048        nan 0.50857143 0.79619048        nan 0.79619048\n",
            " 0.52047619 0.66333333        nan 0.79619048 0.79619048 0.55666667\n",
            " 0.78047619 0.79619048 0.73666667        nan 0.50857143 0.64333333\n",
            "        nan 0.82       0.50857143 0.79571429 0.79619048 0.78142857\n",
            "        nan 0.79619048 0.52142857 0.5352381  0.79619048 0.50857143\n",
            " 0.79619048 0.79619048 0.79619048 0.79619048 0.79619048 0.79619048\n",
            " 0.82238095        nan 0.80285714 0.79619048 0.50857143 0.79619048\n",
            " 0.79619048        nan 0.51              nan 0.81857143 0.79619048\n",
            " 0.79619048        nan 0.79619048 0.58380952 0.79619048        nan\n",
            " 0.79619048 0.71142857 0.50857143 0.78333333 0.78714286 0.79619048\n",
            "        nan 0.72904762 0.79333333 0.79619048 0.79619048 0.79619048\n",
            " 0.79619048 0.62190476 0.50857143 0.50857143 0.51       0.80904762\n",
            " 0.50857143 0.78333333        nan 0.7847619  0.79619048 0.79619048\n",
            "        nan 0.5947619         nan 0.7652381  0.79619048 0.76904762\n",
            " 0.61333333 0.79619048 0.76619048 0.79619048 0.81333333 0.80619048\n",
            "        nan 0.7852381  0.79619048 0.79619048 0.63142857 0.50857143\n",
            " 0.50857143 0.67238095 0.80238095 0.79666667 0.64904762 0.63428571\n",
            " 0.51285714        nan 0.50857143        nan 0.58952381 0.50857143\n",
            " 0.8052381  0.50857143        nan 0.60333333 0.79619048 0.79619048\n",
            " 0.8047619  0.50857143 0.81857143 0.79619048 0.80619048 0.66380952\n",
            " 0.80380952 0.78619048        nan 0.79619048 0.75857143 0.79619048\n",
            " 0.50857143 0.79619048 0.79619048        nan        nan        nan\n",
            "        nan 0.79619048 0.79619048 0.79619048 0.79619048 0.82095238\n",
            " 0.79619048 0.79619048 0.52285714        nan 0.79619048 0.77428571\n",
            "        nan        nan        nan        nan 0.79619048 0.79619048\n",
            " 0.79619048 0.77047619 0.69285714 0.50857143 0.82238095        nan\n",
            " 0.50857143 0.55666667 0.79619048 0.79619048 0.65857143 0.58619048\n",
            "        nan 0.79619048 0.76428571 0.79619048 0.50857143 0.79619048\n",
            "        nan 0.50857143 0.79619048 0.79619048 0.50857143 0.79619048\n",
            "        nan        nan 0.50857143 0.82       0.79619048 0.50857143\n",
            " 0.79619048 0.75142857 0.50857143 0.58619048 0.51714286 0.7652381\n",
            " 0.79619048 0.56333333 0.50857143        nan 0.79619048 0.79952381\n",
            "        nan 0.82285714        nan 0.79619048 0.79619048        nan\n",
            " 0.79619048 0.59142857 0.79666667        nan        nan 0.79619048\n",
            " 0.79619048 0.79047619        nan 0.79619048 0.77761905 0.79619048\n",
            " 0.50857143 0.79619048 0.50857143 0.50857143 0.81333333        nan\n",
            " 0.69714286 0.76428571 0.50857143 0.79619048 0.79619048 0.79619048\n",
            "        nan 0.81333333 0.50857143 0.50857143 0.80428571 0.65714286\n",
            " 0.80761905 0.62       0.50857143 0.78285714 0.79619048 0.8052381\n",
            " 0.50857143        nan 0.79619048 0.79619048 0.79619048 0.79\n",
            " 0.70428571 0.66809524 0.79619048        nan 0.79619048 0.79619048\n",
            "        nan 0.79619048 0.50857143 0.79619048 0.76952381        nan\n",
            " 0.50857143 0.50857143 0.79619048 0.76428571 0.54761905 0.79619048\n",
            " 0.50857143 0.71       0.82333333        nan 0.82142857        nan\n",
            " 0.55666667 0.50857143 0.79619048 0.79619048        nan        nan\n",
            " 0.79619048 0.79619048 0.79       0.50857143 0.50857143 0.82333333\n",
            "        nan        nan 0.79619048 0.5747619  0.79619048 0.79619048\n",
            " 0.50857143 0.50857143 0.75285714 0.79619048 0.79619048        nan\n",
            " 0.82190476 0.81761905 0.58761905        nan 0.51285714 0.79619048\n",
            " 0.81952381 0.82095238        nan 0.79619048        nan 0.79619048\n",
            " 0.82238095 0.79619048 0.79619048 0.50857143 0.80761905 0.77428571\n",
            " 0.65              nan 0.79952381 0.82285714 0.82190476 0.51\n",
            "        nan        nan 0.50857143 0.82190476 0.79619048 0.79619048\n",
            " 0.79619048 0.79619048        nan 0.82095238 0.79619048 0.53047619\n",
            "        nan 0.79619048 0.79285714 0.79619048 0.55666667 0.79619048\n",
            " 0.79619048 0.69904762]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores hiperparámetros para Regresión Logística: {'C': 52.97573637713819, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REGRESIÓN LOGÍSTICA:\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "#Modelo de regresión logística\n",
        "modeloLR = None\n",
        "modeloLR = LogisticRegression( C= 52.97573637713819, max_iter=1000, solver= 'liblinear', penalty= 'l2')\n",
        "modeloLR.fit(trainEmb, y_train)\n",
        "\n",
        "print('LR: Train-accuracy: %.2f%%' % (100*modeloLR.score(trainEmb, y_train)))\n",
        "print('LR: Val-accuracy: %2.f%%' % (100*modeloLR.score(valEmb, y_val)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predLR = modeloLR.predict(testEmb)\n",
        "print('\\nMatriz de confusión con el mejor modelo de regrecion logistica:')\n",
        "print(confusion_matrix(y_test, predLR, labels=[0,1]))\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ],
      "metadata": {
        "id": "ycwjD8ztGOL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791190a5-e30c-4aab-c881-5d1bf09bf3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: Train-accuracy: 87.81%\n",
            "LR: Val-accuracy: 81%\n",
            "\n",
            "Matriz de confusión con el mejor modelo de regrecion logistica:\n",
            "[[180  36]\n",
            " [ 44 190]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kcoHGWF0eJh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Busqueda de hiperparametros para obtener un mejor modelo RF:\n",
        "from scipy.stats import loguniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "#Hiperparámetros para Random Forest\n",
        "hiperparametros_RF = {\n",
        "    'n_estimators': [50, 150, 100, 150, 200],\n",
        "    'max_depth': [None, 2, 3, 5, 8, 13, 21],\n",
        "    'min_samples_split': [2, 3, 5, 8, 13, 21],\n",
        "    \"criterion\": ['gini', 'entropy', 'log_loss']\n",
        "}\n",
        "\n",
        "\n",
        "#Inicializar modelos\n",
        "modelo_RF = RandomForestClassifier()\n",
        "\n",
        "\n",
        "#Inicializar búsqueda de cuadrícula para cada modelo con sus respectivos hiperparámetros\n",
        "busqueda_RF = RandomizedSearchCV(modelo_RF, hiperparametros_RF, n_iter=250, random_state=248, n_jobs=-1 ,cv=5)\n",
        "\n",
        "#Ajustar búsqueda de cuadrícula a los datos\n",
        "busqueda_RF.fit(trainEmb, y_train)\n",
        "\n",
        "\n",
        "#Obtener los mejores hiperparámetros para cada modelo\n",
        "mejores_hiperparametros_RF = busqueda_RF.best_params_\n",
        "\n",
        "print(\"Mejores hiperparámetros para random forest:\", mejores_hiperparametros_RF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1_rnd-Dh_20",
        "outputId": "7b5d683a-fea9-4f04-9d3a-5ea4afbff923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores hiperparámetros para random forest: {'n_estimators': 200, 'min_samples_split': 8, 'max_depth': 13, 'criterion': 'entropy'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BOSQUE ALEATORIO (Random Forest):\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "# Crear y entrenar el modelo de bosque aleatorio\n",
        "modeloRF = RandomForestClassifier(max_depth = 13, min_samples_split = 8, n_estimators = 200, criterion= 'entropy')\n",
        "modeloRF.fit(trainEmb, y_train)\n",
        "\n",
        "print('LR: Train-accuracy: %.2f%%' % (100*modeloRF.score(trainEmb, y_train)))\n",
        "print('LR: Val-accuracy: %2.f%%' % (100*modeloRF.score(valEmb, y_val)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predRF = modeloRF.predict(testEmb)\n",
        "print('\\nMatriz de confusión con el mejor modelo de random forest:')\n",
        "print(confusion_matrix(y_test, predRF, labels=[0,1]))\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ],
      "metadata": {
        "id": "N4n70GHW0sl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a32544-899b-4e21-8b14-95067714fde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: Train-accuracy: 99.90%\n",
            "LR: Val-accuracy: 79%\n",
            "\n",
            "Matriz de confusión con el mejor modelo de random forest:\n",
            "[[167  49]\n",
            " [ 50 184]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pregunta - 9:**"
      ],
      "metadata": {
        "id": "WDIiSHvg0_hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Reporte del mejor modelo.\n"
      ],
      "metadata": {
        "id": "dJJtALGZHrGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generar el reporte de clasificación LR\n",
        "reporte_clasificacionLR = classification_report(y_test, predLR, target_names=['negativo', 'positivo'])\n",
        "\n",
        "# Imprimir el informe de clasificación LR\n",
        "print(\"Reporte de Clasificacion para regresion logistica:\")\n",
        "print(reporte_clasificacionLR)\n",
        "\n",
        "\n",
        "\n",
        "# Generar el reporte de clasificación RF\n",
        "reporte_clasificacionRF = classification_report(y_test, predRF, target_names=['negativo', 'positivo'])\n",
        "\n",
        "# Imprimir el informe de clasificación FR\n",
        "print(\"Reporte de Clasificacion para Random forest:\")\n",
        "print(reporte_clasificacionRF)\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ],
      "metadata": {
        "id": "ETv4VLjP1GYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4939ad7d-2df4-4b4d-e03c-bc9b735726bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reporte de Clasificacion para regresion logistica:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.80      0.83      0.82       216\n",
            "    positivo       0.84      0.81      0.83       234\n",
            "\n",
            "    accuracy                           0.82       450\n",
            "   macro avg       0.82      0.82      0.82       450\n",
            "weighted avg       0.82      0.82      0.82       450\n",
            "\n",
            "Reporte de Clasificacion para Random forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.77      0.77      0.77       216\n",
            "    positivo       0.79      0.79      0.79       234\n",
            "\n",
            "    accuracy                           0.78       450\n",
            "   macro avg       0.78      0.78      0.78       450\n",
            "weighted avg       0.78      0.78      0.78       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pregunta - 10:**"
      ],
      "metadata": {
        "id": "YCkh2WfN1MC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Incluye tus comentarios finales de la actividad.\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "Los modelos de regresión logística y random forest obtuvieron mejores resultados que en la ocasión anterior.\n",
        "\n",
        "Sin embargo, estos modelos son muy simples para obtener resultados superiores a los obtenidos, lo que implica un límite en la exactitud que se puede alcanzar con ellos.\n",
        "\n",
        "Aun así, estos modelos resultan ser muy útiles para este análisis, pues con la cantidad limitada de datos y el poder de procesamiento limitado, lograron obtener una exactitud respetable.\n",
        "\n",
        "En varias ocasiones para este caso, la regresión logística resultó ser mejor que el bosque aleatorio, a diferencia de la ocasión anterior. Esto puede deberse a que trabajar ahora con vectores es más fácil para el modelo obtener una \"dirección\" que indica el sentido del comentario, a diferencia del modelo de random forest, que resultó ser mejor en la ocasión anterior al tomar decisiones sobre los valores de las matrices.\n",
        "\n",
        "En cuanto al procesamiento de los datos, al usar lematización y convertir las contracciones comunes en el idioma inglés a las palabras completas, se pudo mejorar el desempeño de los modelos.\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++"
      ],
      "metadata": {
        "id": "4ySFuDQtVuK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fin de la Actividad de vectores Embebidos - FastText**"
      ],
      "metadata": {
        "id": "bgKHmQTbWJT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliografia:\n",
        "\n",
        "\n",
        "\n",
        "*   FastText. (n.d.). https://fasttext.cc/\n",
        "*   Google Code Archive - Long-term storage for Google Code Project Hosting. (n.d.). https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZW6pOKJ5HtSf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWtIFiiuHvLn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}